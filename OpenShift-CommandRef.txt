Authorization:

# to Login from command prompt (below are some of the ways)
> oc login -u <username> -p <password> <openshift cluster apiserver url>
> oc login --insecure-skip-tls-verify --server=https://master.na311.openshift.opentlc.com:443
> oc login -u <my-user-name> --server="<master-api-public-addr>:<master-public-port>
> oc login --token=<token> --server=https://api.shared.na.openshift.opentlc.com:6443

# to get the bearer token which can be used for authorization to access openshift resources without logging in.
> oc whoami -t

# to access apis using token ( this is calling the users api here)
curl -H "Authorization: Bearer 8tKuwU8didUK9xwc_xS2XYGX4TziwVkb-8NDIXAPCkU" 
"https://api.shared.na.openshift.opentlc.com:6443/apis/user.openshift.io/v1/users/~"

# to logout
> oc logout

# get list of scc (security context constraint)
oc get scc

-------------------------------------------------------------------------------------------------------------------------------------
Basic Operations like create project, delete them etc :

Tips:
-p is to set parameter values defined by the template
-n is the project name where the command will run and access/modify resources from
-f is file or filepath
-l is label
-o is output(like : output format which can be yaml, jsonpath, json, or output only the name of pods , etc)
-w is watch (like : you want to get the output of pod status when the status changes, so -w will look for any change in the pod status)
--help to get details about a command (ex: oc get pods --help)
-e key=value is the environment variable to be set
--key=value is used to pass in arguments and values in a configuration
--parametername=key=value is used to pass key value to an existing openshift parameter.

oc get : for getting information about resources (limited info)
oc describe : to get detailed information about the resource
oc delete : for deleting resources
oc create : to create resources
oc set : to set environment variable

Short Hands:
svc - service
bc - build configs
dc - deployment configs
rc - replication controller


# get list of templates in openshift
oc get templates -n openshift

#get all resources of the project
oc get all

#to get pods running on the project
oc get pods
oc get pods -w

#examine the pods with labels
oc get pods --show-labels

#explore the details of one of the pods.
oc get pods <pod-name> -o yaml

#explore the replicationcontroller object
oc get rc <replication controller name> -o yaml

#delete all pods with a label app=app-cli
oc delete pod -l app=app-cli

# force delete pods
oc delete pod/<pod name> --grace-period=0 --force

#get the details about the selectors of a service
oc describe svc app-cli | grep Selector

#scaling the number of pods (here we are scaling it to 2)
oc scale dc app-cli-1 --replicas=2

#details of the deploymentconfig
oc get dc <deployment config name> -o yaml

#get details of a service
oc get svc mysql -o yaml
oc get svc/mysql

# to get list of only running pods
oc get pods --field-selector status.phase=Running

#create new project
oc new-project <project-name> --description="Some Description" --display-name="Cat of the Day - Prod"


# get list of projects
> oc get projects
> oc projects

# to delete a project
> oc delete project <project name>

# delete all projects
>oc delete project --all

#switch to a specific project
> oc project <name of the project>

# to get route on command line for a project
oc get route <app-service-name> -n <project name> -o template --template='{{.spec.host}}'
oc get routes -n <project name>
oc get route openshift-tasks -n <projectname> -o jsonpath='{.spec.host}{"\n"}'

#get route details
oc get route <route name> -o yaml
oc get route
oc get route/<route name>
oc describe route/<route name>

#get service
oc get svc

#create a readiness proble
oc set probe dc/app-cli --readiness --get-url=http://xyz.com:8080/health --initial-delay-seconds=5

#rollback a deployment to the earlier one
oc rollback app-cli

#creating a Horizontal Pod Autoscaler (HPA)
oc autoscale dc/app-cli --min 2 --max 5 --cpu-percent=75

#Setting a cpu request for HPA
oc set resources dc/app-cli --requests=cpu=400m

#get HPA event 
oc describe hpa app-cli

# to load test a horizontal Pod Autoscaler using "apache benchmark tool"
Installing the tool : sudo apt install apache2-utils
To load test: ab -n 50000 -c 500 http://<the url to load test>

-n : the total number of requests to be fired
-c : number of concurrent requests to be fired at a time

# to retag an image with a different tag name (retag from cotd2:latest to cotd2:testready )
oc tag cotd2:latest cotd2:testready -n pipeline-roy-dev

# To examine the image stream and get details about it
oc describe is cotd2:latest -n pipeline-roy-dev

#Create a persistent volume claim of 4G and connect it to /data:
oc set volume dc/gogs --add --overwrite --name=gogs-volume-1 --type persistentVolumeClaim --claim-size=4G --claim-name=gogs-data

#Create the ConfigMap with the app.ini file and mount it as a volume into the pod:
oc create configmap gogs --from-file=app.ini
oc set volume dc/gogs --add --overwrite --name=config-volume -m /opt/gogs/custom/conf/ -t configmap --configmap-name=gogs
rm -f app.ini

#Set the MAVEN_MIRROR_URL environment variable for the openshift-tasks build configuration:
oc set env bc openshift-tasks MAVEN_MIRROR_URL=http://nexus3.opentlc-shared.svc.cluster.local:8081/repository/maven-all-public


# Registry
Info: Each openshift cluster has a built in registry which holds multiple repositories for storing the container
images. Generally there is one repository for each OCP project(aka namespace).

The naming convention of the image is:
<registry identifier>/<repository identifier>/<image name>:<image tag>

##External route url: default-route-openshift-image-registry.<cluster_name>
url: default-route-openshift-image-registry.apps.ocp42-poc.ocppocexample.com
Login to Registry Command:
podman login -u (oc whoami) -p $(oc whoami -t) --tls-verify=false default-route-openshift-image-registry.apps.ocp42-poc.ocppocexample.com:443

##Internal url: image-registry.openshift-image-registry.svc:5000
Login to Registry command:
$ oc login -u kubeadmin -p <password_from_install_log>
$ podman login -u kubeadmin -p $(oc whoami -t) image-registry.openshift-image-registry.svc:5000

##Complete Image url:
<external / internal registry url>/project/image:tag

##After logging in to registry you can perform below actions.

docker push <external / internal registry url>/project/image:tag

docker tag <some image> image-registry.openshift-image-registry.svc:5000/openshift/image:Latest

docker image-registry.openshift-image-registry.svc:5000/openshift/image:latest



---------------------------------------------------------------------------------------------------------------------------------------
User Administration, roles, policy and permission grants :

# to get list of users
> oc get users


# to add cluster admin role to an existing user
> oc adm policy add-cluster-role-to-user <role> <username>
Ex: oc adm policy add-cluster-role-to-user cluster-admin administrator

# add view role to the default service account
oc adm policy add-role-to-group view system:serviceaccounts:<projectname>-n <projectname>


# enable the jenkins service account to manage resources in another project "pipeline-roy-test"
oc policy add-role-to-user edit system:serviceaccount:pipeline-roy-dev:jenkins -n pipeline-roy-test

# enable the project "pipeline-roy-test" to pull image from "pipeline-roy-dev" project
oc policy add-role-to-group system:image-puller system:serviceaccounts:pipeline-roy-test -n pipeline-roy-dev

#Give the service account the correct permissions to edit objects in this project to allow Jenkins to build and deploy the application
oc policy add-role-to-user edit system:serviceaccount:$GUID-cicd:jenkins -n $GUID-tasks
-----------------------------------------------------------------------------------------------------------------------------------------
Create Databases :

# mongodb creation from a template in local
oc process -f OpenshiftConfigSamples/mongodb-persistent.yaml -p CATALOG_DB_USERNAME=mongo -p 
CATALOG_DB_PASSWORD=mongo -n <project name> | oc create -f - -n <project name>

#create a mysql persistent db
oc new-app mysql-persistent --name mysqldb -e MYSQL_HOST=mysql -e MYSQL_DATABASE=pizzadb -e MYSQL_USER=admin -e MYSQL_PASSWORD=admin123 -e MYSQL_ROOT_PASSWORD=root

#create a mysql ephemeral db
oc new-app mysql-ephemeral --name mysqldb -e MYSQL_HOST=mysql -e MYSQL_DATABASE=pizzadb -e MYSQL_USER=admin -e MYSQL_PASSWORD=admin123 -e MYSQL_ROOT_PASSWORD=root

# Running MYSQL DB using an image
oc new-app -e MYSQL_USER=admin -e MYSQL_PASSWORD=admin123 -e MYSQL_DATABASE=pizzadb openshift/mysql-56-centos7

#Create postgres db
oc new-app postgresql-persistent --param POSTGRESQL_DATABASE=gogs --param POSTGRESQL_USER=gogs --param POSTGRESQL_PASSWORD=gogs --param VOLUME_CAPACITY=4Gi -lapp=postgresql_gogs

oc new-app -e POSTGRESQL_USER=luke -ePOSTGRESQL_PASSWORD=secret \
             -ePOSTGRESQL_DATABASE=my_data openshift/postgresql-92-centos7 \
             --name=my-database

-----------------------------------------------------------------------------------------------------------------------------------------
Secrets, ConfigMaps and Environment Variables:

## Secrets::
1) How are secrets created ?

i) from Command Line by passing them as Literals
Command: >oc create secret generic test-secret --from-literal=username=<user_name> --from-literal=password="<password>"
(advisable to use password value in quotes as there could be special characters)

This command can be used to create username and password for basic authentication, using the type will validate for the right key names
Command: >oc create secret generic <secret_name> --from-literal=password=<token> --from-literal=username=<user_name> --type=kubernetes.io/basic-auth

ii) From a file(any format) and then create the secret by passing the file which has the secrets.
Command: >oc create secret generic test-secret --from-file=testfile.txt --type=Opaque

iii) From a kubernetes / openshift configuration file.
 a) below in data section the values are base64 encoded
 b) below in stringData section the values are plain text strings, not encoded.
 c) Type is Opaque, that means any key and value can be added, no validation on the key name and value is done
Command: >oc create -f test-secret.yml
Example:: (filename: test-secret.yml)
apiVersion: v1
kind: Secret
metadata:
  name: test-secret
  namespace: my-namespace
type: Opaque 
data: 
  username: dmFsdWUtMQ0K 
  password: dmFsdWUtMg0KDQo=
stringData: 
  hostname: myapp.mydomain.com 

Example2:: (this will create all the secret under onekey config.yaml(this is like a definition file having all the secrets)
apiVersion: v1
kind: Secret
metadata:
  name: mysecret
type: Opaque
stringData:
  config.yaml: |-
    apiUrl: "https://my.api.com/api/v1"
    username: {{username}}
    password: {{password}}


2) How are secrets assigned to Pods to access ?

i) by passing them as environment variables to deploymentsconfigurations
-- can be assigned from command line
CommandLine: > oc set env dc/printenv --from=secret/printenv-secret
adding the secret to deploymentconfig as environment variable

>oc set env dc/printenv --from=secret/printenv-secret --prefix=MYSQL_
Adding the secret to deploymentconfig as environment variable after adding a prefix MYSQL_

-- can be assigned by adding the secret to the deployment configuration file used to spin up the pods.
spec:
    containers:
    - env:
      - name: MYAPP_SECRET_TOKEN
        valueFrom:
          secretKeyRef:
	    name: test-secret
            key: username     
    image: "fedora:29"
    name: my_app

ii) by putting the secret in a file, and mounting the file in a volume which is associated with the pod

-- can be assinged from command line
oc set volume dc/some-app --add --name=secret-volume --mount-path=/opt/app-root/db/ --secret-name=db-secret    
 
-- can be assigned by adding the file to the deployment configuration file used to spin up the pods.
volumeMounts:
        # name must match the volume name below
        - name: secret-volume
          mountPath: /etc/secret-volume
  # The secret data is exposed to Containers in the Pod through a Volume.
  volumes:
    - name: secret-volume
      secret:
        secretName: test-secret

volumeMounts:
          - name: github-user 
            mountPath: "/deployments/github" 
            readOnly: true
      volumes:
      - name: github-user
        secret:
          secretName: spring-github-demo 
          items:
          - key: github.user 
            path: user 
          - key: github.token 
            path: token 

3) How are secrets assiged to builds (for example to pull codes from private repo, the access key to the repo are stored as secrets and passed during builds)
i) by passing them as environment variables to buildconfigs

-- can be assigned from command line
Command 1: To pass the build secret from command line when creating a new buildconfig
oc new-build \
    openshift/wildfly-101-centos7~https://github.com/wildfly/quickstart.git \
    --context-dir helloworld --build-secret “secret-mvn” \
    --build-config-map "settings-mvn"

Command2: oc set build-secret --source bc/sample-build basicsecret
This is to set a source clone secret to access repositories in case of private repos

-- can be assigned by adding the secret as evnironment variable to the buildconfig file used to spin up the pods.
Example:
apiVersion: v1
kind: BuildConfig
metadata:
  name: secret-example-bc
spec:
  strategy:
    sourceStrategy:
      env:
      - name: MYVAL
        valueFrom:
          secretKeyRef:
            key: hostname
            name: test-secret


Example: To add source secret from buildconfig file
apiVersion: "v1"
kind: "BuildConfig"
metadata:
  name: "sample-build"
spec:
  output:
    to:
      kind: "ImageStreamTag"
      name: "sample-image:latest"
  source:
    git:
      uri: "https://github.com/user/app.git"
    sourceSecret:
      name: "basicsecret"



## ConfigMaps:
1) How are configmaps created ?

i) from Command Line by passing them as Literals
Command: >oc create configmap db-info --from-literal=dbname=pizzadb


ii) Store the configmap in a file(any format) and then create the configmap by passing the file as parameter.
Command: >oc create configmap ui-config --from-file=style.properties

iii) By creating a kubernetes / openshift configuration file.

Command: >oc create -f test-configmap.yml
Example:: (filename: test-configmap.yml)
apiVersion: v1
kind: ConfigMap
metadata:
  name: db-info
  namespace: default
data:
  dbname: pizzadb

Example2:: (this will create all the secret under onekey config.yaml(this is like a definition file having all the secrets)
kind: ConfigMap
apiVersion: v1
metadata:
  creationTimestamp: 2017-03-17T19:12:11Z
  name: sample-config
  namespace: default
data:
  example.property.1: hello
  example.property.2: world
  example.property.file: |-
    property.1=value-1
    property.2=value-2
    property.3=value-3


2) How are configmaps assigned to Pods to access ?

i) by passing them as environment variables to deploymentsconfigurations
-- can be assigned from command line

Command2: oc env dc/myapp --from=configmap/sample-config
The above command will add the configmap to deployment configuration's environment variable


-- can be assigned by adding the configmap to the deployment configuration file used to spin up the pods.
 env:
   - name: SPECIAL_LEVEL_KEY
     valueFrom:
       configMapKeyRef:
        name: special-config
        key:  special.how

ii) by putting the secret in a file, and mounting the file in a volume which is associated with the pod
-- can be assinged from command line
>oc set volumes dc/todo-app --add --name=configmap-volume --mount-path=/opt/app-root --configmap-name=ui-config
   
 
-- can be assigned by adding the file to the deployment configuration file used to spin up the pods.
                  volumeMounts:
		  - name: application-config-vol
                    mountPath: /deployments/config
        volumes:
        - name: application-config-vol
          configMap:
	    name: fooditemsorderdeliveryapi-props-configmap
            items:
            - key: application.properties
              path: application.properties


## Environment variables

1) Command:> oc set env dc/printenv APP_VAR_1=Value1 APP_VAR_2=Value2
This will set the keys APP_VAR_1 and APP_VAR_2 as environment variables to the deploymentconfiguration.

2) oc set env dc/printenv READ_FROM_FILE=/data/configfile.txt
Set an environment variable to read from the file

3) oc new-app -ePOSTGRESQL_USER=luke -ePOSTGRESQL_PASSWORD=secret \
             -ePOSTGRESQL_DATABASE=my_data openshift/postgresql-92-centos7 \
             --name=my-database
This will create an app and add the environment variables (-e)

4)oc set env dc/printenv READ_FROM_FILE=/data/configfile.txt
Set an environment variable to read from the file:


** NOTE : if a configmap or secrets contains more than one value, on adding the configmap as an environment variable to a deployment config,
will add all the keys and values, each as a single entitiy.
There is also a naming convention that OC follows, all key named as "hello.world" will be automatically added as "HELLO_WORLD" environment
variable NAME.
-----------------------------------------------------------------------------------------------------------------------------------------
# edit secrets
oc edit secrets <secret-name>

# cli to set build secret for pulling code from private repo
oc set build-secret --source bc/<build config name> <secret name>

# getting a secret as yaml output format
oc get secret mysecret -o yaml

# checking list of secrets assigned as env variable to deploymentconfig
oc set env dc/printenv --list

#getting a config map as  yaml output format
oc get configmaps special-config -o yaml

#Editing a configmap
oc edit dc/pizza-order-delivery-api

#Creating configmap from file
oc create configmap app-config --from-file=OpenshiftConfigSamples/app-configmap.yaml -n <projectname>

#To view the configmap entries created above
oc get configmap app-config -o yaml -n <project name>

#Creating configmap from key and value passed from command line
oc create configmap cart-service --from-literal=catalog.service.url=http://catalog-service-cd-friday-coolstore-catalog.apps.na311.openshift.opentlc.com

# createan environment variable for a deployment config
oc set env dc/printenv APP_VAR_1=Value1 APP_VAR_2=Value2

#delete the second environment variable above (notice the minus(-) sign after the environment variable key)
oc set env dc/printenv APP_VAR_2-

#Create a config map from two environment variables
oc create configmap printenv-config --from-literal=APP_VAR_3=Value3 --from-literal=APP_VAR_4=Value4

#Set an environment variable to read from the file
oc set env dc/printenv READ_FROM_FILE=/data/configfile.txt

#create a secret from a file 
echo 'r3dh4t1!' > ./password.txt   
echo 'admin' > ./user.txt
oc create secret generic printenv-secret --from-file=app_user=user.txt --from-file=app_password=password.txt

#create a secret from literal
oc create secret generic github-secret --from-literal=username=shuroych --from-literal=password='<password or token>'

# create a basic authentication secret
oc create secret new-basicauth github-secret --username=shuroych --password='<token>'

#validate the secret
oc get secret printenv-secret -o yaml

#As secrets are base64 encoded, so decode the secret
echo "<base 64 encoded secret>" | base64 --decode

#add the secret to the deployment config
oc set env dc/<deployment config name> --from=secret/printenv-secret

# verify the list of environment variables tagged to a deployment config
oc set env dc/printenv --list

#Set the same secrets for the MySQL database by adding the MYSQL_ prefix:
oc set env dc/printenv --from=secret/printenv-secret --prefix=MYSQL_

# Mount the new database secret as a volume into the printenv deployment configuration 
# and set the READ_FROM_FILE variable to point to the app_db_url file in that volume:
oc set volume dc/printenv --add --overwrite --name=db-config-volume -m /dbconfig/ --secret-name=printenv-db-secret
oc set env dc/printenv READ_FROM_FILE=/dbconfig/app_db_url
---------------------------------------------------------------------------------------------------------------------------------------
Java Application Build and Deployment using fabric8 plugin now called "jkube openshift" plugin :

# Using fabric8 plugin now called as jkube openshift plugin:
git url:https://github.com/eclipse/jkube
documentation url : https://htmlpreview.github.io/?https://github.com/eclipse/jkube/blob/master/openshift-maven-plugin/doc/index.html#goals-build

#Deploying a java app using fabric8 plugin using maven command from development system
mvn clean oc:deploy -Popenshift


----------------------------------------------------------------------------------------------------------------------------------------
Create,Build and Deployments:

# Creating and deploying a java app and passing username pwd in environment variable, using fabric8 java s2i image
oc new-app -e DB_USERNAME=admin -e DB_PASSWORD=admin123 -e MY_DATABASE_SERVICE_HOST=mysql -e MY_DATABASE_SERVICE_PORT=3306 
-e JAVA_OPTIONS='-Dspring.profiles.active=openshift'
fabric8/s2i-java:3.0-java8~https://shuroych:<token>@github.ibm.com/shuroych/fooditemsorderdeliveryapi.git

#create a java spring boot app using redhat s2i image (notice there is a tild(~) before after the s2i image and before the github url)
oc new-app redhat-openjdk18-openshift~<git hub url used to clone the repo) 
ex:oc new-app redhat-openjdk18-openshift~https://github.com/jboss-openshift/openshift-quickstarts.git 

#create a java springboot app using context directory (context directory is used if the project is not in the root folder of git repo)
oc new-app registry.access.redhat.com/redhat-openjdk-18/openjdk18-openshift~https://github.com/fmarchioni/masterspringboot.git 
--context-dir=demo-docker --name=springboot-demo-docker
# then expose the java app
oc expose svc/springboot-demo-docker

-- you can also add  (-e MAVEN_ARGS='-Popenshift') to pass in maven arguments, currently not needed above as the above s2i image of java
by default runs the maven command on the source code using profile as openshift

#Create and Deploy an angular app from ibm github using docker strategy.(remember the Dockerfile should be present in the project folder)
oc new-app https://shuroych:<token>@github.ibm.com/shuroych/pizza-order-delivery-ui.git --strategy=docker

#create a Jenkins service
oc new-app jenkins-persistent -p ENABLE_OAUTH=false -e JENKINS_PASSWORD=openshiftpipelines -n pipeline-roy-dev

#deploy an image to a project. here the image cotd2:testready is deployed from project pipeline-roy-dev to another project pipeline-roy-test
# note, for deploying image from one project to another, the rbac policy for system:image-puller should be given to the other project
oc new-app pipeline-roy-dev/cotd2:testready --name=cotd2 -n pipeline-roy-test

#create a new deployment from docker image
oc new-app --docker-image=quay.io/gpte-devops-automation/ocp-probe:v0.5 --name=blue

#create routes
oc expose service cotd2 -n pipeline-roy-dev
oc expose service <service name> -n <project name>
oc expose svc/<service name>

# to trigger a build
> oc rollout latest <deployment name>
ex: oc rollout latest dc/simple-webapp-dock

# to see the history of build
> oc rollout history <deployment name>

# to describe a deployment
> oc rollout describe <deployment name>
oc describe <deployment name>

#to check the status of the deployment
oc rollout status deployment <deployment name>
oc rollout status dc <deployment name>

#to scale a deployment
oc scale deployment <deployment name> --replicas=3
oc scale dc/<deployment name> --replicas=3

#to edit a deployment
oc edit deployment <deployment name>
oc edit dc/<deployment name>

# to undo a deployment
> oc rollout undo <deployment name>

# to see the ipaddress assigned to a pod
oc get pods -o wide

# list all pods from all namespaces/projects | show only first 15 pods from the list)
oc get pods --all-namespaces | head -n 15

# disable automatic deployment for a project (project : pipeline-roy-dev)
oc get dc cotd2 -o yaml -n pipeline-roy-dev | sed 's/automatic: true/automatic: false/g' | oc replace -f -
oc set triggers dc openshift-tasks --manual

#create a deployment/service/route or any openshift object from a file
oc create -f <filename>.yaml

#to edit an deployment config
oc edit dc <deployment config name>

# get all resources for an app
oc get all --selector app=pizza-order-delivery-ui

# delete all resources for an app
oc delete all --selector app=pizza-order-delivery-ui

# Autoscale pods using HPA(horizontal Pod Autoscaler)
oc autoscale dc/example --min=5 --max=7 --cpu-percent=75

#Autoscale pods on the node only if it can guarantee say 400millicores
oc set resources dc/example --requests=cpu=400m

#Autoscale get details
oc describe hpa example

# To view resource capacity on a node for HPA
oc describe node <node name>

#to test a autoscaled cluster using "Apache Benchmark Tool"
ab -n 50000 -c 500 <url of the request>
-n : total number of requests to be fired
-c : number of requests fired concurrently
------------------------------------------------------------------------------------------------------------------------------------
View Logs, check info and troubleshooting

# to check build logs
oc logs -f build/cotd2-1 -n <project-name>

# to check logs of a pod
oc logs -f <pod name>

# to check the build-config logs
oc logs -f bc/fooditemsorderdeliveryapi

#to check applicaiton status
oc status

# open a shell in the running pod
oc rsh <pod name>
--------------------------------------------------------------------------------------------------------------------------------------  




